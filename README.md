# pupil_labs_pico_flexx_validation
p.wagner@unsw.edu.au 
p.wagner@bhvi.org  
------------------------------------------------------------------------------------------
This readme describes steps to extract depth data from point cloud videos, here at 
point for regard (PoR). This software requires data generated by pupil the open source 
eye-tracking software of pupil-labs.com, from the picoflexx depth plugin. 
Picoflexx is a time of flight camera from pmd Technologies AG. 
Furthermore, following scripts have been used to validate gaze position and point cloud
position matching.  
--------------------------------------------------------------------------------------------

1. in pupil player: export pupil_positions.csv,  gaze_positions.csv, blinks.csv

2. A) extract_gaze_depth_from_PoR.m
Iterates through all participants and tests, uses “royale_LEVEL1_extract_depth_data_at_PoR.m” 
to extract depth data at point of regard. 

2. B) royale_LEVEL1_extract_depth_data_at_PoR.m 

Use modified pmd Technologies AG script to access point cloud and record depth data at PoR. 
-	Allocate timestamp to point cloud frame from world_timestamps.npy
-	Match gaze coordinates from temporal nearest gaze timestamp from gaze_positions.csv 
-	record depth data for various inclusion circles 
3. A) find_all_rrf.m 
- employ royale_LEVEL1_extract_target_data.m to find all targets in each point cloud frame  
3. B) royale_LEVEL1_extract_target_data.m

- select range of target spheres +/- 10 cm
- convert point cloud to a .png to be able to use a circle finder to detect targets 
- sort targets to individual identifiers

Now the found target positions can be used to monitor head movements in regard to the testing 
field by comparing target positions to there average. 

4. acc_testing_q_head_cc.ipynb
Visualise data from accuracy testing. 
-	Gaze confidence 
-	Gaze count per target 
-	Selected radius for all targets 
-	Depth point inclusion per gaze point 
-	Gaze positions within pico flexx grid – head-movement compensated 
-	Detected head movements 

5. MAE_allPX_allTrials_withCI.ipynb
Visualize all mean data from all participants all trials and 95% confidence interval per target. 
Visualize mean of all detected target position. 

6. MAE_px_rec.ipynb
Visualize results of mean average error for all participants and tests per participant and over 
eccentricity from point cloud center.  

7. PLPF_Vidoes_time_matching.ipynb
Extracts video frame identifier from source file, matches timestamps for eye and world-videos 
and displays deltas. 

8. GDDA_library 
Library for frequently used functions. 

9. led_sequence_random.ipynb
Finds random sequence of LEDs (uneven number) for accuracy testing. 
- optional one or two sided (interconnected, each with every LED)

10. ledTestingToF_V03_targets_only.ino
Arduino code to activate LEDs in in given order.  
